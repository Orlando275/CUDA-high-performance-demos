<!-- Banner -->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=rect&color=gradient&height=100&section=header&text=CUDA%20High-Performance%20Demos&fontSize=40&animation=fadeIn" />
</p>

## ğŸ¯ Project Overview

**CUDA High-Performance Demos** is a collection of CUDAâ€accelerated vector and matrix routines showcasing advanced optimization techniques:

- Shared memory tiling for coalesced global loads  
- Warpâ€level optimization to minimize divergence  
- Tiling strategies to maximize data reuse and throughput  

Each demo comes in a baseline version and a sharedâ€memoryâ€optimized (`SH_`) variant, so you can compare performance gains side by side.

---

## ğŸ“¥ Installation & Setup

### 1. Prerequisites

- NVIDIA GPU with Compute Capability â‰¥ 5.0  
- CUDA Toolkit (â‰¥ 10.0) installed and in your `PATH`  
- Docker installation

### 2. Clone this repository

```bash
git clone https://github.com/Orlando275/CUDA-high-performance-demos.git
cd CUDA-high-performance-demos
```

---

## ğŸ³ Docker Image

You can pull and run the latest version of the CUDA-high-performance-demos from Docker Hub:

```bash
docker pull orlando2705/cuda-high-perf-demos:v1.1
docker run --rm --gpus all orlando2705/cuda-high-perf-demos:v1.1
```
---

## ğŸƒ How to Run


### Example: matrix multiplication (Shared Memory)
```bash
nvcc SH_matrix_multiplication.cu -o matrix_multiplication 
./matrix_multiplication
```

### Example imput
```bash
200  20  120    # M x N, N x P
```

### Example: vector sum
```bash
./sum_of_vectors
10000000
./SH_total_vector_sum
10000000
```

---

## âœ¨ Features

- **SH_ variants** use shared memory tiling to reduce global memory traffic.  
- **Warpâ€level primitives** for fast reductions and minimized divergence.  
- **Parameterizable block/grid sizes** for autoâ€tuning.  
- **Sideâ€byâ€side** baseline vs. optimized implementations for performance comparison.  

---

## ğŸ“‚ Project Structure
<pre>
CUDA-high-performance-demos/
â”œâ”€â”€ Vectors/
â”‚   â”œâ”€â”€ normalize_vector.cu
â”‚   â”œâ”€â”€ SH_normalize_vector.cu
â”‚   â”œâ”€â”€ SH_total_vector_sum.cu
|   â””â”€â”€ sum_of_vectors.cu
â”œâ”€â”€ Matrices/
â”‚   â”œâ”€â”€ matrix_multiplication.cu
â”‚   â””â”€â”€ SH_matrix_multiplication.cu
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
</pre>

---

## ğŸš€ GPU Kernel Performance Report

### 1ï¸âƒ£ Vector Addition â€“ Naive Implementation
- **Input size:** `33,554,432` elements  
- **Kernel time:** `54.28 ms`  
- **Description:**  
  Each thread processes a single element. This approach suffers from poor scalability and inefficient memory usage.

![Exercise of sum of vector without optimization(course)](https://github.com/user-attachments/assets/29d169f4-57fc-4b81-9411-22c7d65616aa)

---

### 2ï¸âƒ£ Vector Addition â€“ Optimized with Grid-Stride Loop

- **Input size:** `33,554,432` elements  
- **Kernel time:** `1.61 ms`  
- **Description:**  
  Using the **grid-stride loop** pattern, each thread handles multiple elements.  
  This drastically improves resource utilization and reduces execution time by **~34Ã—** compared to the naive version.
![sum of vectors with optimization ](https://github.com/user-attachments/assets/08de80a8-e59a-4b0e-976a-2d7000e4694e)

---

### 3ï¸âƒ£ Vector Normalization â€“ Shared Memory + Warp-Level Optimization

- **Input size:** `33,554,432` elements  
- **Kernel time (all stages):** `2.98 ms`  
- **Description:**  
  - Uses **binary reduction** in shared memory to accumulate partial sums.  
  - Applies **warp shuffle intrinsics** (`__shfl_down_sync`) for efficient intra-warp reduction.  
  - Demonstrates how combining **shared memory** and **warp-level primitives** results in high-performance kernels for reduction-type operations.
![ Normalize Vector with Shared Memory](https://github.com/user-attachments/assets/dc5d86bd-39cd-474c-b71a-e3fb7812c04b)

---

## ğŸ“Š Performance Comparison

| Implementation                                           | Input Size     | Kernel Time | Speedup vs Naive |
|----------------------------------------------------------|---------------:|------------:|-----------------:|
| Vector Addition â€“ Naive                                  | 33,554,432     | 54.28 ms    | 1Ã—               |
| Vector Addition â€“ Grid-Stride Loop                       | 33,554,432     | 1.61 ms     | ~34Ã—             |
| Vector Normalization â€“ Shared Memory + Warp Optimization | 33,554,432     | 2.98 ms     | ~18Ã—             |

---

### ğŸ’¡ Key Takeaways:
- **Grid-stride loops** are a simple yet powerful optimization for memory-bound kernels.
- **Shared memory + warp-level primitives** are essential for high-performance reductions.
- Even with the same input size, kernel design can yield **orders of magnitude** performance differences.

---

## ğŸš€ How It Works

- **Baseline Execution**: Runs kernels that read and write directly from global memory without shared memory usage.  
- **Shared Memory Tiling**: Optimized versions split data into tiles stored in shared memory, processed cooperatively by threads, then written back to global memory.  
- **Warp-Level Optimization**: Uses warp-level primitives like `__shfl_down_sync` to perform fast intraâ€‘warp reductions without shared memory.  
- **Performance Comparison**: Each demo includes both baseline and optimized versions to measure execution time, throughput, and the impact of shared memory and warp-level operations.  

## ğŸ›  Technologies Used

- **CUDA C/C++** â€“ Core language for implementing highâ€‘performance GPU kernels.  
- **NVIDIA CUDA Toolkit** â€“ Provides compiler (`nvcc`), runtime libraries, and development utilities.  
- **Shared Memory & Warp-Level Primitives** â€“ GPU optimization techniques for reduced latency and higher throughput.  
- **CUDA Events** â€“ For precise kernel execution timing and performance measurement.  
- **Docker** â€“ Containerization for consistent, portable builds and environment setup across systems.

## ğŸš€ Future Improvements
- Optimize kernels using **LLVM** and custom **PTX** tuning for lowâ€‘level performance gains.  
- Implement **multiâ€‘GPU synchronization** and collective operations via **NVIDIA NCCL** for distributed execution.  
- Add support for advanced AIâ€‘related kernels such as **softmax** and common **loss functions** (e.g., crossâ€‘entropy, MSE).  
- Extend profiling and benchmarking suite to measure scalability across multiple GPUs.  
- Provide **Docker** setup for reproducible, portable GPU development environments.  

---
